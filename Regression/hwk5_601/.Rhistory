n=50  #sample size
p=10000 # dimension
mu<-sample(x = 1:p,size = p)# different generation dist's mean
x<-sapply(mu, function(x) rnorm(n,mean = x,sd = 3))
beta_t<-rep(0,p)
beta_t[1:3]<- c(1,2,3)
beta_t
beta_t[1:10]
n=50  #sample size
p=10000 # dimension
mu<-sample(x = 1:p,size = p)# different generation dist's mean
x<-sapply(mu, function(x) rnorm(n,mean = x,sd = 3))
beta_t<-rep(0,p)
beta_t[1:3]<- c(1,2,3)#true beta
y<-x%*%beta_t+rnorm(n) #y=x*b + epsilon
d<- as.data.frame(x)
d<- cbind(y,d)
lm(y~.,data = d)#full model
full<-lm(y~.,data = d)#full model
full$coefficients[1:10]
full$coefficients[1:20]
y<-2+x%*%beta_t+rnorm(n) #y=a0 + x*b + epsilon
d<- as.data.frame(x)
d<- cbind(y,d)
full<-lm(y~.,data = d)#full model
full$coefficients[1:10]
full$coefficients[1:20]
result<-summary(full)
full<-lm(y~.,data = d)#true model
full$coefficients[1:10]
result1<-summary(full)
result1$sigma
result1$cov.unscaled
d
?curve
k=19000
rho<-function(x){#define function Tukey's rho
if( abs(x)<= k ) return(x^2)
else return(2*k*abs(x) - k^2)
}
curve(rho, from = -100000, to = 100000 )
par(mfrow=c(1,2))
curve(rho, from = -100000, to = 100000 )
curve(rho, from = -k, to = k )
curve(rho, from = -k-1000, to = k+1000 )
k=19000
rho<-function(x){#define function Tukey's rho
if( abs(x)<= k ){
return(x^2)
} else{
return(2*k*abs(x) - k^2)
}
}
par(mfrow=c(1,2))
curve(rho, from = -100000, to = 100000 )
curve(rho, from = -k-1000, to = k+1000 )
rho(k)
rho(k+)
rho(k+1)
rho(k+2)
rho(k+43)
2*k*abs(x) - k^2
rho(k+43)
2*k*abs(k+43) - k^2
curve(rho, from = -100000, to = 100000 )
rho<-function(x){#define function Tukey's rho
if( identical(abs(x)<= k,TRUE) ){
return(x^2)
} else{
return(2*k*abs(x) - k^2)
}
}
par(mfrow=c(1,2))
curve(rho, from = -100000, to = 100000 )
curve(rho, from = -k-1000, to = k+1000 )
curve(rho, from = -k, to = k )
k=19000
rho<-function(x){#define function Tukey's rho
if( identical(abs(x)<=k,TRUE) ){
return(x^2)
} else{
return(2*k*abs(x) - k^2)
}
}
par(mfrow=c(1,2))
curve(rho, from = -100000, to = 100000 )
curve(rho, from = -k-1000, to = k+1000 )
rho<-function(x){#define function Tukey's rho
if( abs(x)<= k ) return(x^2)
else return(2*k*abs(x) - k^2)
}
par(mfrow=c(1,2))
curve(rho, from = -k-1000, to = k+1000 )
curve(rho,-k,k)
rho<-function(x){#define function Tukey's rho
#   if( abs(x)<= k ) return(x^2)
#   else return(2*k*abs(x) - k^2)
ifelse(abs(x)<= k,x^2,2*k*abs(x) - k^2)
}
par(mfrow=c(1,2))
curve(rho, from = -100000, to = 100000 )
curve(rho, from = -k-1000, to = k+1000 )
abline(v=c(-k,k))
curve(rho, from = -100000, to = 100000 )
abline(v=c(-k,k))
curve(rho, from = -100000, to = 100000 )
abline(v=c(-k,k),lty=2 )
under<-lm(y ~ . ,data = d[1:10])
under$coefficients
full$coefficients[1:10]
result2<-summary(under)
result2
?rt
new<-rt(n,df=1,ncp = 3)
d.new<-cbind(d,new)
new<-rt(n,df=1,ncp = 3)
d.new<-cbind(new,d)
over<-lm(y ~ . ,data = d.new)
over$coefficients
result2<-summary(over)
result2
over$coefficients[1:10]
over$coefficients[1:11]
library(MASS)
d<-read.csv("pgatour2006.csv",header = T);head(d)
dd<-d[-c(1,2,4,11)]
dim(dd)
names(dd)
?stepAIC
lm<- lm(log(PrizeMoney)~.,data = dd)
stepAIC(lm )
stepAIC(lm, trace = FALSE)
install.packages("bestglm")
library(leaps)
?regsubsets
opt<-regsubsets(og(PrizeMoney)~.,data = dd,
nbest = 1,       # 1 best model for each number of predictors
nvmax = NULL,    # NULL for no limit on number of variables
force.in = NULL, force.out = NULL,
method = "exhaustive")
opt<-regsubsets(log(PrizeMoney)~.,data = dd,
nbest = 1,       # 1 best model for each number of predictors
nvmax = NULL,    # NULL for no limit on number of variables
force.in = NULL, force.out = NULL,
method = "exhaustive")
plot(opt, scale = "adjr2", main = "Adjusted R-square")
par(mfrow=c(1,1))
plot(opt, scale = "adjr2", main = "Adjusted R-square")
stepAIC(lm, trace = FALSE)
?stepAIC
?regsubsets
library(bestglm)
?bestglm
head(dd)
pairs(dd)
library(dplyr)
dd<-mutate(y=log(PrizeMoney))
dd<-mutate(y=log(PrizeMoney),.data = dd)
head(dd)
dd<- sselect(dd,-PrizeMoney)
dd<- select(dd,-PrizeMoney)
head(dd)
aic<-bestglm(Xy = dd,
family = gaussian,
IC = "AIC",
method = "exhaustive")
aic$BestModel
?regsubsets
aic<-bestglm(Xy = dd,
family = gaussian,
IC = "BIC",
method = "exhaustive")
aic$BestModel
aic<-bestglm(Xy = dd,
family = gaussian,
IC = "BIC",
aic<-bestglm(Xy = dd,
family = gaussian,
IC = "AIC",
method = "backward")
aic$BestModel
bic<-bestglm(Xy = dd,
family = gaussian,
IC = "BIC",
method = "backward")
bic$BestModel
aic<-bestglm(Xy = dd,
family = gaussian,
IC = "AIC",
method = "forward")
aic$BestModel
bic<-bestglm(Xy = dd,
family = gaussian,
IC = "BIC",
method = "forward")
bic$BestModel
dim(dd)
full$coefficients[1:10]
result1$sigma
result2<-summary(under)
result2
result2$sigma
result2$coefficients
result1$coefficients[1:10,]
result2$coefficients[1:10,]
result3<-summary(over)
result3$coefficients[1:11,]
muu<-2+x%*%beta_t
y<- lapply(seq(100),function(x) return(muu+rnorm(n)))
class(y)
y[[1]]
y<-muu+rnorm(n) #y=2 +x1 +2*x2 +3*x3 +epsilon(~N(0,1))
y
yy<- lapply(seq(100),function(x) return(muu+rnorm(n)))
beta0123<- matrix(0,nrow = 100,ncol = 4)
beta0123
beta0123<- matrix(0,nrow = 100,ncol = 5)
for(i in seq(100)){
y<-yy[[i]]
d<- cbind(y,d)
full<-lm(y~.,data = d)#true model
result1<-summary(full)
beta0123[i,]<-result1$coefficients[1:5,1]
}
beta0123
i=1
y<-yy[[i]]
d<- cbind(y,d)
full<-lm(y~.,data = d)#true model
result1<-summary(full)
y<-yy[[i]]
d<- cbind(y,d)
d<- as.data.frame(x)
d<- cbind(y,d)
full<-lm(y~.,data = d)#true model
result1<-summary(full)
beta0123[i,]<-result1$coefficients[1:5,1]
muu<-2+x%*%beta_t
d<- as.data.frame(x)
n=50  #sample size
p=10000 # dimension
mu<-sample(x = 1:p,size = p)# different generation dist's mean
x<-sapply(mu, function(x) rnorm(n,mean = x,sd = 3))
beta_t<-rep(0,p)
beta_t[1:3]<- c(1,2,3)#true beta
muu<-2+x%*%beta_t
d<- as.data.frame(x)
yy<-lapply(seq(100),function(x) return(muu+rnorm(n)))
under_fit<-function(y){
d<- cbind(y,d)
under<-lm(y~.,data = d[1:5])# underfitting
result<-summary(under)
return(result$coefficients[1:5,1])
}
beta0123<-sapply(yy,  FUN = under_fit )
beta0123
beta0123<-sapply(yy,  FUN = under_fit);beta0123[,1:100]
beta0123<-sapply(yy,  FUN = under_fit);beta0123[,c(1,100)]
sample.mean <- rowMeans(beta0123)
(sample.mean <- rowMeans(beta0123))
(sample.var <- apply(beta0123, 1, var))
(bias<-sample,mean-c(2,1,2,3,0))
(bias<-sample.mean-c(2,1,2,3,0))
full_fit<-function(y){
d<- cbind(y,d)
under<-lm(y~.,data = d)# underfitting
result<-summary(under)
return(result$coefficients[1:5,1])
}
beta0123<-sapply(yy,  FUN = under_fit);beta0123[,c(1,100)]
d
names(d)
names(d)[1]
names(d)[2]
full_fit<-function(y){
d<- cbind(y,d)
under<-lm(y~.,data = d)# underfitting
result<-summary(under)
return(result$coefficients[1:5,1])
}
beta0123<-sapply(yy,  FUN = under_fit);beta0123[,c(1,100)]
(sample.mean <- rowMeans(beta0123))
(bias<-sample.mean-c(2,1,2,3,0))#bias
under_fit<-function(y){
beta0123<-sapply(yy,  FUN = under_fit);beta0123[,c(1,100)]
(sample.mean <- rowMeans(beta0123))
(bias<-sample.mean-c(2,1,2,3,0))#bias
full_fit<-function(y){
d<- cbind(y,d)
under<-lm(y~.,data = d)# underfitting
result<-summary(under)
return(result$coefficients[1:5,1])
}
beta0123<-sapply(yy,  FUN = full_fit);beta0123[,c(1,100)]
n=50  #sample size
p=10000 # dimension
mu<-sample(x = 1:p,size = p)# different generation dist's mean
x<-sapply(mu, function(x) rnorm(n,mean = x,sd = 3))# x
beta_t<-rep(0,p)
beta_t[1:3]<- c(1,2,3)#true beta
muu<-2+x%*%beta_t
d<- as.data.frame(x)
yy<-lapply(seq(100),function(x) return(muu+rnorm(n)))
#y=2 +x1 +2*x2 +3*x3 +epsilon(~N(0,1))
full_fit<-function(y){
d<- cbind(y,d)
under<-lm(y~.,data = d)# underfitting
result<-summary(under)
return(result$coefficients[1:5,1])
}
beta0123<-sapply(yy,  FUN = full_fit);beta0123[,c(1,100)]
(sample.mean <- rowMeans(beta0123))
(bias<-sample.mean-c(2,1,2,3,0))#bias
(sample.var <- apply(beta0123, 1, var))#sample variance of true model's estimate
new<-rt(n,df=1,ncp = 3) #overfitting
d.new<-cbind(new,d)
over_fit<-function(y){
d<- cbind(y,d.new)
under<-lm(y~.,data = d)
result<-summary(under)
return(result$coefficients[c(1,3,4,5,6),1])
}
beta0123<-sapply(yy,  FUN = over_fit);beta0123[,c(1,100)]
(sample.mean <- rowMeans(beta0123))
(bias<-sample.mean-c(2,1,2,3,0))#bias
(sample.var <- apply(beta0123, 1, var))#sample variance of over-fitting model's estimate
n=500  #sample size
p=10000 # dimension
mu<-sample(x = 1:p,size = p)# different generation dist's mean
x<-sapply(mu, function(x) rnorm(n,mean = x,sd = 3))# x
beta_t<-rep(0,p)
beta_t[1:3]<- c(1,2,3)#true beta
muu<-2+x%*%beta_t
d<- as.data.frame(x)
yy<-lapply(seq(100),function(x) return(muu+rnorm(n)))
full_fit<-function(y){
d<- cbind(y,d)
under<-lm(y~.,data = d)# underfitting
result<-summary(under)
return(result$coefficients[1:5,1])
}
beta0123<-sapply(yy,  FUN = full_fit);beta0123[,c(1,100)]
