---
title: "hwk3"
author: "Dingxian Cao"
date: "October 29, 2015"
output: word_document
---

# 5  
```{r}
n=100#sample size
dat<- data.frame(x1=rnorm(n,3,2),x2=rexp(n,1),x3=rgamma(n,2,3)) 
betaT<-c(beta0=2,beta1=1.2,beta2=-1.4,beta3=-0.5)
muT<-as.vector(model.matrix(~x1+x2+x3,dat) %*% betaT)#EY  

sigmasq<-runif(n,0.5,3)#variance
sigma<-sqrt(sigmasq)
yy<- muT+sigma*rnorm(n)# ONE realization  with different variance
lm(yy~.,data=dat)  
lm(yy~.,data=dat,weights = 1/sigmasq)

S<-10000 #simulation realization number
YY<- muT + sigma * matrix(rnorm(n * S), nrow = n,ncol = S)

beta_diff<-function(y){
  lmi<-lm(y~.,data = dat)
  wlmi<-lm(y~.,data = dat,weights = 1/sigmasq)
  c(lmi$coefficients-betaT,wlmi$coefficients-betaT)
}
beta_dif<-apply(YY, 2,beta_diff)

beta_dif_lm<-beta_dif[1:4,]
beta_dif_wlm<-beta_dif[5:8,]

rowMeans(beta_dif_lm^2)#beta mse OF OLS
rowMeans(beta_dif_wlm^2)#beta mse OF WLS
```

# 6  
### a  

```{r}
ants <- read.table("thatch_ant_c5del.txt", sep='', header=TRUE)
pairs(ants)
```

>There is no explicit relationship between Headwidth and colony or distance.  

### b 

```{r}
ants2<-read.table("thatch_ant_c5del.txt", sep='', header=TRUE,
                  colClasses = c("factor","numeric","numeric","numeric","numeric"))
#should take colony number as factor  

str(ants2)
result<-lm(Headwidth~0+Colony+Distance,data = ants2)
summary(result)
```

```{r}
design<-model.matrix(~Colony+Distance-1,data = ants2)
dim(design)
design[design[,11]==4
       ,colnames(design)=="Colony4"]
```

> the coefficients of the each colony means the average headwidth in that colony at distance 0. And the coefficient of distance means that the average headwidth will grow 0.167 per meter.

```{r}
m1<-lm(Headwidth~Colony+Distance-1,data = ants2)
m2<-lm(Headwidth~1,data = ants2)
anova(m1,m2)
```

>H0: beta1.=beta2=0  
>test statistic= $F=\frac{(RSS2-RSS1)/11}{RSS1/(1104-11)}=5.47646$. it's distribution is F(11,1093), the result is to reject the Null hypothesis which means headwidth is related to colony and distance.   

```{r}
m1<-lm(Headwidth~Colony+Distance-1,data = ants2)
m2<-lm(Headwidth~Colony-1,data = ants2)
anova(m1,m2)
```

>H0: beta2=0  
>test statistic= $F=\frac{(RSS2-RSS1)/1}{RSS1/(1104-11)}=18.83143$. it's distribution is F(1,1093), the result is to reject the Null hypothesis which means headwidth is related to distance.   

### c  

```{r,eval=FALSE}
library(lme4)
library(car)
m1<-lm(Headwidth~Colony+Distance-1,data = ants2)
m1$coefficients
rhs <- rep(0,9)
hm<-rbind(c(0,1,0,0,0,0,0,0,-1,0,0)
          ,c(1,-2,0,0,0,0,0,0,0,0,0)
          ,c(0,-2,1,0,0,0,0,0,0,0,0)
          ,c(0,-2,0,1,0,0,0,0,0,0,0)
          ,c(0,-2,0,0,1,0,0,0,0,0,0)
          ,c(0,-2,0,0,0,1,0,0,0,0,0)
          ,c(0,-2,0,0,0,0,1,0,0,0,0)
          ,c(0,-2,0,0,0,0,0,1,0,0,0)
          ,c(0,-2,0,0,0,0,0,0,0,1,0))
linearHypothesis(m1,hm,rhs)
```
>we should reject null hypothesis.

### d  

```{r}
plot(ants2$Headwidth,ants2$Mass)
m1_e<-lm(Headwidth~Colony+Distance+Mass-1,data = ants2)
summary(m1_e)
```  

### e  
```{r}
library(reshape2)
library(dplyr)
library(ggplot2)

ants3<-read.table("thatch_ant_c5del.txt", sep='', header=TRUE,
                  colClasses=c("factor","factor","numeric","numeric","numeric"))

av1<-aov(Headwidth~Colony*Distance,data = ants3)#two factors

result<-model.tables(av1,type = "means")
interact<-result$tables$`Colony:Distance`
interact<-interact[c(3,10,7,5,8,9,2,6,4,1),]  

inter<-matrix(as.vector(interact),nrow=10)
colnames(inter)<-colnames(interact);rownames(inter)<-rownames(interact)
inter<- as.data.frame(t(inter))

inter$distance<-rownames(inter)
inter<-melt(inter)
inter<-rename(inter,colony=variable,headwidth.mean=value)
ggplot(inter,aes(x =headwidth.mean,y=colony,group=distance)) + geom_path(aes(lty=distance))

```  

>reproduce the plot of the problem.  

```{r} 
m1<-aov(Headwidth~Colony*Distance,data = ants3)  
m2<-aov(Headwidth~1,data = ants3)
anova(m1,m2)
```

>H0:the effect of colony and distance is not significant.  
>result: reject the nul hypothesis, so the data supports the general observation from this plot.  

>Another way to use variable distance: we can treat as not a factor but a normal variable into the model.  

### f 

```{r}  
m1<-lm(Headwidth~Colony+Distance-1,data = ants2)#one factors
result<-summary(m1)
interact<-result$coefficients[-11,1]
interact<-interact[c(3,10,7,5,8,9,2,6,4,1)]  
inter<- as.data.frame((interact))
inter$colony<-rownames(inter)
colnames(inter)[1]<-"headwidth.mean"
inter<-arrange(inter,headwidth.mean)

plot(inter$headwidth.mean,axes = F,xlab="colony",ylab="headwidth")

lablist.x<-inter$colony
lablist.y<-inter$headwidth.mean
axis(1, at=seq(1, 10, by=1), labels = FALSE)

text(x = seq(1, 10, by=1), par("usr")[3] - 0.2, labels = lablist.x, srt = 45, pos = 1, xpd = TRUE)

axis(2, at=inter$headwidth.mean, labels = FALSE)  

text(y=inter$headwidth.mean, par("usr")[1], labels = round(lablist.y,2), pos = 2, xpd = TRUE) 
box()

m1<-lm(Headwidth~Colony+Distance-1,data = ants2)
m2<-lm(Headwidth~1,data = ants2)
anova(m1,m2)
```

# 7   

>no data on the dropbox  

### a&b  

```{r}
library(car)
DataURL <- "http://www.stat.wisc.edu/~st849-1/data/"
str(ql <- read.table(paste(DataURL, "hmw3q1_data.txt", sep=""), header=TRUE))
plot(ql)

outlierTest(lm(VL~GSS,data = ql))

outlierTest(lm(VL~GSS,data = ql[-28,]))

outlierTest(lm(VL~GSS,data = ql[-c(16,28),]))

outlierTest(lm(VL~GSS,data = ql[-c(6,16,28),]))

outlierTest(lm(VL~GSS,data = ql[-c(6,16,28,44),]))

model<-lm(VL~GSS,data = ql[-c(6,16,28),])
summary(model)
```
### c  

```{r}
par(mfrow=c(2,2))
plot(model,ask = FALSE)
```
>it seems that constant variance and normality assumption are both violated.

### d  

```{r}
b<-boxCox(VL~GSS,data=ql,lambda = seq(-2, 2, 1/10) )
lambda<- b$x[which.max(b$y)]
ql$y<-(ql$VL^lambda-1)/lambda
model2<-lm(y~GSS,data = ql)
summary(model2)
par(mfrow=c(2,2))
plot(model2,ask = FALSE)
```



# 8  

### a   
```{r}
str(br <- read.table("brand_preference.txt", sep="", header=TRUE))
pairs(br)  
```  

### b  

```{r}
model<-lm(Brand_Liking~Moisture_Content+Sweetness,data = br)
summary(model)
```

>keep sweetness equal, the average increase of brand_liking score is 4.43.

### c  

```{r}
par(mfrow=c(1,1))
plot(model$residuals)
abline(h=mean(model$residuals))#E(e)=0

par(mfrow=c(2,2))
plot(model,ask=FALSE)
```  

>it seems the model satisfy the Gauss-Markov assumption.  

### d   
```{r}
library(car)
avPlot(model,"Moisture_Content")
avPlot(model,"Sweetness")
```  

### e  

>According to the added-variable plot, the model in part b is appropriate that both variables are important.  

### f  
```{r}
layout(matrix(1:2,ncol=2))
plot(model,which=c(2,3))
ext_sr<- rstudent(model)#t(16-3-1)
# which(abs(ext_sr)>2)  
(1-pt(abs(ext_sr),df = 16-3-1))<0.1/2#the true are the outliers
```  

>the desicion rule is that if the absolute value of external residual is larger than the critical value(but i use p value instead), we should take it as the outlier. The result shows that the outliers are the 11th and 14th points.   

### g  
```{r}  
par(mfrow=c(1,1))
x<-model.matrix(model)
lev<-hat(x)
plot(lev,ylim = c(0.1,0.5),ylab = "leverage points")
abline(h=(2*3)/16)
```

>there is no leverage point.  

### h 
```{r}
e<-diag(model$residuals)
h<-diag(1/(1-hat(x)))
H<-x%*%solve(t(x)%*%x)%*%t(x)
(cooks<-apply(((h%*%e%*%H)^2)/(3*var(br$Brand_Liking)),1,sum))
par(mfrow=c(2,1))
plot(cooks,main = "by matrix algebra")
plot(cooks.distance(model),main = "by built-in function")

```


# 9   

### a

```{r}
str(hayfever <- within(read.table("hayfever.txt", sep="", header = TRUE),
{
 A <- factor(A)
 B <- factor(B)
 id <- factor(id)
}))

model1<-aov(hours~A*B,data = hayfever)
(effect<-model.tables(model1))
(means<-model.tables(model1,type = "means"))

7.1833+0.65+1.8-0.5083
```

>since the model is $Y=\mu + \alpha + \beta +(\alpha * \beta)+\epsilon$
>from the table we can see that when factor A=2 and factor B=3, the estimated mean is about 9.125.

### b  

```{r}
qqnorm(model1$residuals)
qqline(model1$residuals)
```
Apparently, it violate the nomality assumption.  

### c 

```{r}
levels(hayfever$A)
x<-rep(1:3,3)
y<-as.vector(means$tables$`A:B`)
plot(x,y,pch=1:3,cex=1.2,xlab = "A",ylab = "B")
```
>apparently, there is interaction between A AND B. 

### d&e

```{r} 
summary(model1)
model2<-aov(hours~A+B,data = hayfever)
anova(model1,model2)
```
>they are significant at level of 0.05.













